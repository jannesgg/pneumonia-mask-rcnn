{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"4gty7oH9_Bcc","colab":{}},"cell_type":"code","source":["### Establish the baseline model - treat the whole problem as regression on 20 values (max 4 bounding boxes)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1540717657910,"user_tz":-60,"elapsed":29905,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}},"id":"2SRAKU4DQ6kQ","outputId":"6cfcc813-2ed3-4692-d960-884d35e9018d","colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1540719353082,"user_tz":-60,"elapsed":1126,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}},"id":"E6KPND3AQ6mV","outputId":"06245006-5c21-425f-cca9-3e6f363a09dc","colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["cd '/content/drive/My Drive/Colab Notebooks/dml-project'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/dml-project\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"lyhuhUfN_5J7","colab":{}},"cell_type":"code","source":["\n","### Pre-processing"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"2AkVwfWQqhzF","colab":{}},"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"aCwjDJl9DhJT","colab":{}},"cell_type":"code","source":["df_train = pickle.load(open('./dftrain.pickle','rb'))\n","df_test = pickle.load(open('./dftest.pickle','rb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hBqyVAK837QV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":271},"outputId":"f59cdf71-d5ac-4e15-ed2a-5a007e2efc37","executionInfo":{"status":"ok","timestamp":1540719359105,"user_tz":-60,"elapsed":1655,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["df_train.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patientId</th>\n","      <th>num_bounding_boxes</th>\n","      <th>PatientAge</th>\n","      <th>PatientSex</th>\n","      <th>ViewPosition</th>\n","      <th>class</th>\n","      <th>noopacity_but_not_normal</th>\n","      <th>target</th>\n","      <th>bounding_boxes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>F</td>\n","      <td>PA</td>\n","      <td>No Lung Opacity / Not Normal</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>F</td>\n","      <td>PA</td>\n","      <td>No Lung Opacity / Not Normal</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>M</td>\n","      <td>AP</td>\n","      <td>No Lung Opacity / Not Normal</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>M</td>\n","      <td>PA</td>\n","      <td>Normal</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>F</td>\n","      <td>AP</td>\n","      <td>Lung Opacity</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[152.0, 264.0, 379.0, 213.0], [152.0, 562.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              patientId  num_bounding_boxes  PatientAge  \\\n","0  0004cfab-14fd-4e49-80ba-63a80b6bddd6                   0          51   \n","1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd                   0          48   \n","2  00322d4d-1c29-4943-afc9-b6754be640eb                   0          19   \n","3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5                   0          28   \n","4  00436515-870c-4b36-a041-de91049b9ab4                   2          32   \n","\n","  PatientSex ViewPosition                         class  \\\n","0          F           PA  No Lung Opacity / Not Normal   \n","1          F           PA  No Lung Opacity / Not Normal   \n","2          M           AP  No Lung Opacity / Not Normal   \n","3          M           PA                        Normal   \n","4          F           AP                  Lung Opacity   \n","\n","   noopacity_but_not_normal  target  \\\n","0                         1       0   \n","1                         1       0   \n","2                         1       0   \n","3                         0       0   \n","4                         0       1   \n","\n","                                      bounding_boxes  \n","0                                                 []  \n","1                                                 []  \n","2                                                 []  \n","3                                                 []  \n","4  [[152.0, 264.0, 379.0, 213.0], [152.0, 562.0, ...  "]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"colab_type":"code","id":"jhug5VtIqxqs","colab":{}},"cell_type":"code","source":["def parse_data(df):\n","    \"\"\"\n","    Method to read a CSV file (Pandas dataframe) and parse the \n","    data into the following nested dictionary:\n","\n","      parsed = {\n","        \n","        'patientId-00': {\n","            'dicom': path/to/dicom/file,\n","            'label': either 0 or 1 for normal or pnuemonia, \n","            'boxes': list of box(es)\n","        },\n","        'patientId-01': {\n","            'dicom': path/to/dicom/file,\n","            'label': either 0 or 1 for normal or pnuemonia, \n","            'boxes': list of box(es)\n","        }, ...\n","\n","      }\n","\n","    \"\"\"\n","    # --- Define lambda to extract coords in list [y, x, height, width]\n","    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]\n","\n","    parsed = {}\n","    for n, row in df.iterrows():\n","        # --- Initialize patient entry into parsed \n","        pid = row['patientId']\n","        if pid not in parsed:\n","            parsed[pid] = {\n","                'dicom': '../all/stage_1_train_images/%s.dcm' % pid,\n","                'label': row['Target'],\n","                'boxes': []}\n","\n","        # --- Add box if opacity is present\n","        if parsed[pid]['label'] == 1:\n","            parsed[pid]['boxes'].append(extract_box(row))\n","\n","    return parsed"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"qczEJXSQAF7k","colab":{}},"cell_type":"code","source":["def create_bounding_rows(df_train):\n","    \n","    \"\"\"\n","    Takes each patientId and creates a row of combined bounding boxes and \n","    also includes their confidence scores. All patientId's are \n","    included in one matrix.\n","    This fuction is based on a max of 4 bounding boxes per patientId.\n","    Output: Numpy matrix of shape(len(df_train), 20) \n","    \"\"\"\n","    \n","    # read in the dataframe that will be parsed by the function parse_data(df)\n","    df_boxes = \\\n","    pd.read_csv('./all/stage_1_train_labels.csv')\n","\n","    \n","    # set the length depending on how many bounding boxes we want the model to output\n","    length = 20\n","    \n","    h = np.ones(20)\n","    k = np.zeros(20)\n","\n","    # create an empty numpy matrix matching the size of the output matrix\n","    y = np.zeros((len(df_train),length))\n","\n","    # run the function\n","    # this must be here because this must be run each time this script is run or\n","    # the resulting matrix will have errors.\n","    parsed = parse_data(df_boxes)\n","\n","\n","    for i in range(0,len(df_train)):\n","\n","        # get the patientId\n","        patientId = df_train.loc[i, 'patientId']\n","\n","        # extract the bounding boxes for a particular patient\n","        box = parsed[patientId]['boxes']\n","        if len(box) == 0:\n","\n","            # the first row becomes a dummy row of ones this must be deleted later\n","            # k is an array of zeros\n","            h = np.vstack((h,k))\n","\n","        if len(box) != 0:\n","\n","            # insert 1 as the first entry in each bounding box\n","            # the 1 represents confidence for that bounding box\n","            a=[]\n","            for i in range(0,len(box)):\n","                box[i].insert(0,1)\n","                a = a + box[i]\n","\n","            # calculate how much padding to add\n","            b = length - len(a)\n","\n","            # pad the list because not all lists have 4 bounding boxes\n","            # we want all lists to have the same length\n","            for i in range(0,b):\n","                a.insert(len(a),0)\n","\n","            # reshape to horizontal because the above code makes the list vertical\n","            a = np.array(a).reshape(1,length)\n","            \n","            # stack\n","            h = np.vstack((h,a))\n","\n","    # delete the first row because we added this row just to make the code run\n","    h = np.delete(h, 0, axis=0)\n","    \n","    return h\n","\n","\n","# call the function\n","box_rows = create_bounding_rows(df_train)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"l0_Cpk4LAIGU","colab":{}},"cell_type":"code","source":["# concat box_rows with df_y\n","\n","# put box_rows in a dataframe\n","df_y = pd.DataFrame(box_rows)\n","\n","# rename the columns in df_box_rows\n","new_names = new_names = ['conf_1', 'x_1', 'y_1', 'width_1', 'height_1',\n","           'conf_2', 'x_2', 'y_2', 'width_2', 'height_2',\n","           'conf_3', 'x_3', 'y_3', 'width_3', 'height_3',\n","           'conf_4', 'x_4', 'y_4', 'width_4', 'height_4']\n","df_y.columns = new_names\n","\n","# Let's choose only the first three bounding boxes for each sample\n","df_y = df_y[['conf_1', 'x_1', 'y_1', 'width_1', 'height_1',\n","           'conf_2', 'x_2', 'y_2', 'width_2', 'height_2',\n","            'conf_3', 'x_3', 'y_3', 'width_3', 'height_3',\n","            'conf_4', 'x_4', 'y_4', 'width_4', 'height_4']]\n","\n","# add the patientId column to df_y\n","df_y['patientId'] = df_train['patientId']"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"ABiTHxJ-OXwP","colab":{}},"cell_type":"code","source":["# shuffle df_y\n","from sklearn.utils import shuffle\n","df_y = shuffle(df_y)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1540719382009,"user_tz":-60,"elapsed":4600,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}},"id":"4rg_AefCOgGn","outputId":"d8e125c9-a5ca-4cf2-8fc9-67d69f958285","colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["from numpy.random import seed\n","seed(101)\n","from tensorflow import set_random_seed\n","set_random_seed(101)\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","!pip install pydicom\n","import pydicom\n","import pylab\n","import os\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","from skimage.transform import resize\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","# Don't Show Warning Messages\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import gc; gc.enable()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.2.0)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"HOl3LZ5gOYT_","colab":{}},"cell_type":"code","source":["df_train_images, df_val_images = train_test_split(df_y, test_size=0.20,\n","                                                   random_state=5)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"VvRheySYAL51","colab":{}},"cell_type":"code","source":["df_train_images.reset_index(inplace=True)\n","df_val_images.reset_index(inplace=True)\n","df_train = df_train_images.drop(['index', 'patientId'], axis=1)\n","df_val = df_val_images.drop(['index','patientId'], axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"9L9Qqn5YAXNm","colab":{}},"cell_type":"code","source":["def train_generator(df_train_images, df_train, batch_size, num_rows, num_cols):\n","    \n","    '''\n","    Input: Dataframes, df_train_images and df_train\n","    \n","    Outputs one batch (X_train, y_train) on each iteration of the for loop.\n","    \n","    X_train:\n","    Reads images from a folder, converts the images to a numpy array \n","    with shape: (batch_size, num_rows, num_cols, 1)\n","    \n","    y_train:\n","    Takes data from a pandas dataframe. Converts the data into a numpy array\n","    with shape (batch_size, num_rows, num_cols, 1)\n","    \n","    '''\n","    \n","    \n","    while True: \n","\n","        batch = []\n","        k = 0\n","\n","\n","        # note that we are rounding down.\n","        num_batches = math.ceil(df_train_images.shape[0]/batch_size)\n","\n","        # create an empty numpy array matching the number of images\n","        image_array = np.zeros((batch_size,num_rows,num_cols))\n","\n","\n","\n","        # this loop runs only once each time the next() function is called.\n","        for i in range(0,num_batches): # 20547 rows in train_images. we are using only 20000 of them\n","\n","            if i < num_batches-1:\n","\n","                # [1] Create X_train\n","\n","                # carve out 1000 rows of the 'patientId' column\n","                batch = list(df_train_images['patientId'][k:(i+1)*batch_size])\n","\n","                #for patientId in batch:\n","                for j in range(0,len(batch)):\n","                    patientId = batch[j]\n","\n","\n","                    path = \\\n","                './all/stage_1_train_images/%s.dcm' % patientId\n","\n","                    dcm_data = pydicom.read_file(path)\n","\n","                    # get the image as a numpy array\n","                    image = dcm_data.pixel_array\n","\n","                    # resize the image\n","                    small_image = resize(image,(num_rows,num_cols))\n","\n","                    # add the image to the empty numpy array\n","                    image_array[j,:,:] = small_image\n","\n","                # reshape the array and normalize\n","                X_train = image_array.reshape(batch_size,num_rows,num_cols,1)/255\n","\n","                # [2] Create y_train\n","\n","                # note: Here we use df_train instead of df_train_images\n","                # because we don't want the output to have the patientId column.\n","\n","                # carve out 1000 rows\n","                y_train = df_train[k:(i+1)*batch_size]\n","\n","                # convert to a numpy array\n","                y_train = y_train.values\n","\n","            # to cater for the last batch i.e. the fractional part\n","            if i == num_batches-1: \n","\n","                batch_size_fractional = df_train.shape[0] - (batch_size*(num_batches-1)) # -1\n","\n","                # create an empty numpy array matching the number of images\n","                image_array = np.zeros((batch_size_fractional,num_rows,num_cols))\n","\n","                # select rows from the tail of df_test upwards\n","                batch1 = list(df_train_images['patientId'][-batch_size_fractional:]) #1000\n","\n","                #for patientId in batch:\n","                for j in range(0,len(batch1)):\n","                    patientId = batch1[j]\n","\n","                    path = \\\n","            './all/stage_1_train_images/%s.dcm' % patientId\n","\n","                    dcm_data = pydicom.read_file(path)\n","\n","                    # get the image as a numpy array\n","                    image = dcm_data.pixel_array\n","\n","                    # resize the image\n","                    small_image = resize(image,(num_rows,num_cols))\n","\n","                    # add the image to the empty numpy array\n","                    image_array[j,:,:] = small_image\n","\n","                # reshape the array and normalize\n","                X_train = image_array.reshape(batch_size_fractional,num_rows,num_cols,1)/255\n","\n","                # [2] Create y_train\n","\n","                # note: Here we use df_val instead of df_val_images\n","                # because we don't want the output to have the patientId column.\n","\n","                # carve out 1000 rows\n","                y_train = df_train[-batch_size_fractional:]\n","\n","                # convert to a numpy array\n","                y_train = y_train.values\n","                \n","                print(y_train.shape)\n","\n","\n","            k = k + batch_size\n","\n","            # For testing the generator so we can see how many batches it outputs\n","            # by calling next(). Uncomment the next line for testing.\n","            #print(i)\n","\n","            # Keras requires a tuple in the form (inputs,targets)\n","            yield (X_train.astype(np.float32), {'output1': y_train[:,[0,5,10,15]], 'output2': y_train[:,[1,2,3,4,6,7,8,9,11,12,13,14,16,17,18,19]]})"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"O2BjFrnRAcyA","colab":{}},"cell_type":"code","source":["def val_generator(df_val_images, df_val, batch_size, num_rows, num_cols):\n","    \n","    '''\n","    Input: Dataframes, df_val_images and df_val\n","    \n","    Outputs one batch (X_val, y_val) on each iteration of the for loop.\n","    \n","    X_val:\n","    Reads images from a folder, converts the images to a numpy array \n","    with shape: (batch_size, num_rows, num_cols, 1)\n","    \n","    y_val:\n","    Takes data from a pandas dataframe. Converts the data into a numpy array\n","    with shape (batch_size, num_rows, num_cols, 1)\n","    \n","    '''\n","    \n","    \n","    while True: \n","\n","        batch = []\n","        k = 0\n","\n","        # note that we are rounding up.\n","        num_batches = math.ceil(df_val_images.shape[0]/batch_size)\n","\n","        # Create an empty numpy array that matches the batch size.\n","        image_array = np.zeros((batch_size,num_rows,num_cols))\n","\n","\n","         # this loop runs only once each time the next() function is called.\n","        for i in range(0,num_batches): \n","            \n","            if i < num_batches-1:\n","\n","                # [1] Create X_train\n","\n","                # carve out a batch of rows of the 'patientId' column\n","                batch = list(df_val_images['patientId'][k:(i+1)*batch_size])\n","\n","                #for patientId in batch:\n","                for j in range(0,len(batch)):\n","                    patientId = batch[j]\n","\n","                    path = \\\n","            './all/stage_1_train_images/%s.dcm' % patientId\n","\n","                    dcm_data = pydicom.read_file(path)\n","\n","                    # get the image as a numpy array\n","                    image = dcm_data.pixel_array\n","\n","                    # resize the image\n","                    small_image = resize(image,(num_rows,num_cols))\n","\n","                    # add the image to the empty numpy array\n","                    image_array[j,:,:] = small_image\n","\n","                # reshape the array and normalize\n","                X_val = image_array.reshape(batch_size,num_rows,num_cols,1)/255\n","\n","                # [2] Create y_train\n","\n","                # note: Here we use df_val instead of df_val_images\n","                # because we don't want the output to have the patientId column.\n","\n","                # carve out 1000 rows\n","                y_val = df_val[k:(i+1)*batch_size]\n","\n","                # convert to a numpy array\n","                y_val = y_val.values\n","\n","             # to cater for the last batch i.e. the fractional part\n","            if i == num_batches-1: \n","\n","                batch_size_fractional = df_val.shape[0] - (batch_size*(num_batches-1)) \n","\n","                # create an empty numpy array matching the number of images\n","                image_array = np.zeros((batch_size_fractional,num_rows,num_cols))\n","\n","                # select rows from the tail of df_test upwards\n","                batch1 = list(df_val_images['patientId'][-batch_size_fractional:]) \n","\n","                #for patientId in batch:\n","                for j in range(0,len(batch1)):\n","                    patientId = batch1[j]\n","\n","                    path = \\\n","            './all/stage_1_train_images/%s.dcm' % patientId\n","\n","                    dcm_data = pydicom.read_file(path)\n","\n","                    # get the image as a numpy array\n","                    image = dcm_data.pixel_array\n","\n","                    # resize the image\n","                    small_image = resize(image,(num_rows,num_cols))\n","\n","                    # add the image to the empty numpy array\n","                    image_array[j,:,:] = small_image\n","\n","                # reshape the array and normalize\n","                X_val = image_array.reshape(batch_size_fractional,num_rows,num_cols,1)/255\n","\n","                # [2] Create y_train\n","\n","                # note: Here we use df_val instead of df_val_images\n","                # because we don't want the output to have the patientId column.\n","\n","                # carve out a batch of rows\n","                y_val = df_val[-batch_size_fractional:]\n","\n","                # convert to a numpy array\n","                y_val = y_val.values\n","\n","\n","            k = k + batch_size\n","\n","            # For testing the generator so we can see how many batches it outputs\n","            # by calling next().\n","            #print(i)\n","\n","            # Keras requires a tuple in the form (inputs,targets)\n","            yield (X_val.astype(np.float32), {'output1': y_val[:,[0,5,10,15]], 'output2': y_val[:,[1,2,3,4,6,7,8,9,11,12,13,14,16,17,18,19]]})"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"f3ilkH7NAgtM","colab":{}},"cell_type":"code","source":["def test_generator(df_test, batch_size, num_rows, num_cols):\n","    \n","    \"\"\"\n","    Input: Dataframe df_test.\n","    \n","    Outputs one batch (X_test) on each iteration of the for loop.\n","    \n","    X_test:\n","    Reads images from a folder, converts the images to a numpy array \n","    with shape: (batch_size, num_rows, num_cols, 1)\n","    \n","    \"\"\"\n","\n","    batch = []\n","    k = 0\n","    \n","    # note that we are rounding up.\n","    num_batches = math.ceil(df_test.shape[0]/batch_size)\n","\n","    # create an empty numpy array matching the number of images\n","    image_array = np.zeros((batch_size,num_rows,num_cols))\n","    \n","    # this loop runs only once each time the next() function is called.\n","    for i in range(0,num_batches):\n","        \n","        if i < num_batches-1:\n","        \n","            # [1] Create X_test\n","\n","            # carve out a batch of rows of the 'patientId' column\n","            batch = list(df_test['patientId'][k:(i+1)*batch_size]) #1000\n","\n","            #for patientId in batch:\n","            for j in range(0,len(batch)):\n","                patientId = batch[j]\n","\n","                path = \\\n","        './all/stage_1_test_images/%s.dcm' % patientId\n","\n","                dcm_data = pydicom.read_file(path)\n","\n","                # get the image as a numpy array\n","                image = dcm_data.pixel_array\n","\n","                # resize the image\n","                small_image = resize(image,(num_rows,num_cols))\n","\n","                # add the image to the empty numpy array\n","                image_array[j,:,:] = small_image\n","\n","            # reshape the array and normalize\n","            X_test = image_array.reshape(batch_size,num_rows,num_cols,1)/255\n","            \n","        # to cater for the last batch i.e. the fractional part\n","        if i == num_batches-1: \n","            \n","            batch_size_fractional = df_test.shape[0] - (batch_size*(num_batches - 1))\n","            \n","            # create an empty numpy array matching the number of images\n","            image_array = np.zeros((batch_size_fractional,num_rows,num_cols))\n","            \n","            # select rows from the tail of df_test upwards\n","            batch = list(df_test['patientId'][-batch_size_fractional:]) #1000\n","\n","            \n","            for j in range(0,len(batch)):\n","                patientId = batch[j]\n","\n","                path = \\\n","        './all/stage_1_test_images/%s.dcm' % patientId\n","\n","                dcm_data = pydicom.read_file(path)\n","\n","                # get the image as a numpy array\n","                image = dcm_data.pixel_array\n","\n","                # resize the image\n","                small_image = resize(image,(num_rows,num_cols))\n","\n","                # add the image to the empty numpy array\n","                image_array[j,:,:] = small_image\n","\n","            # reshape the array and normalize\n","            X_test = image_array.reshape(batch_size_fractional,num_rows,num_cols,1)/255\n","            \n","        \n","        # For testing the generator so we can see how many batches it outputs\n","        # by calling next(). Uncomment the next line for testing.\n","        #print(i)\n","        \n","        k = k + batch_size\n","        \n","        # Keras requires a tuple in the form (inputs,targets)\n","        yield (X_test.astype(np.float32))\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"XyyrT5AoCOvL","colab":{}},"cell_type":"code","source":["########################\n","# INPUTS\n","\n","# Set the batch sizes:\n","\n","train_batch_size = 128\n","val_batch_size = 128\n","test_batch_size = 100\n","\n","# Set the image size:\n","\n","num_rows = 128\n","num_cols = 128\n","\n","#########################\n","\n","# train_generator\n","train_gen = \\\n","train_generator(df_train_images, df_train, train_batch_size, num_rows, num_cols)\n","\n","num_train_samples = df_train.shape[0]\n","\n","num_train_batches = math.ceil(num_train_samples/train_batch_size) # round down\n","\n","\n","# val_generator\n","val_gen = \\\n","val_generator(df_val_images, df_val, val_batch_size, num_rows, num_cols)\n","\n","num_val_samples = df_val.shape[0]\n","\n","num_val_batches = math.ceil(num_val_samples/val_batch_size) # round down\n","\n","# test_generator\n","test_gen = \\\n","test_generator(df_test, test_batch_size, num_rows, num_cols)\n","\n","num_test_samples = df_test.shape[0]\n","\n","num_test_batches = math.ceil(num_test_samples/test_batch_size) # round up"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"wcNIC-eGW8XS","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"6159b1e4-08ca-4a8f-bcb8-7439559b0c51","executionInfo":{"status":"ok","timestamp":1540719408625,"user_tz":-60,"elapsed":1082,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["# Model Architecture\n","\n","\n","from keras.models import Sequential, Model, Input\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, Flatten, UpSampling2D,  Multiply, Lambda, merge, Activation\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"kygSNgrEkStr","colab_type":"code","colab":{}},"cell_type":"code","source":["input_layer = Input(shape=(num_rows, num_cols, 1))\n","\n","x = BatchNormalization(momentum=0.99)(input_layer)\n","x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","#x = BatchNormalization(momentum=0.99)(x)\n","x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","#x = UpSampling2D(2**2)(x)\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","\n","out1 = Dense(4, activation='sigmoid', name='output1')(x)\n","out2 = Dense(16, activation='relu', name='output2')(x)\n","model = Model(inputs=input_layer, outputs=[out1,out2])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3a22pyFekStu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":495},"outputId":"735f9c4b-a034-4908-cbfb-5f0757ea1956","executionInfo":{"status":"ok","timestamp":1540719412794,"user_tz":-60,"elapsed":1278,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 128, 128, 1)  4           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 126, 126, 32) 320         batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 63, 63, 32)   0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 61, 61, 32)   9248        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 28800)        0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 256)          7373056     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","output1 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","output2 (Dense)                 (None, 16)           4112        dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 7,387,768\n","Trainable params: 7,387,766\n","Non-trainable params: 2\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"4HsJMYpykSty","colab_type":"code","colab":{}},"cell_type":"code","source":["Adam_opt = Adam(lr=1e-2, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n","model.compile(optimizer=Adam_opt, loss={'output1': 'binary_crossentropy', 'output2': 'mse'}, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1540555521563,"user_tz":-120,"elapsed":17003,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}},"id":"To5ASRmjPHP0","outputId":"024f0952-0ecf-496d-e5bb-f479a606394e","colab":{"base_uri":"https://localhost:8080/","height":594}},"cell_type":"code","source":["filepath = \"model_3.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]\n","\n","history = model.fit_generator(generator=train_gen, \n","                        steps_per_epoch=num_train_batches, \n","                        epochs=3, \n","                        verbose=1, \n","                        callbacks=callbacks_list, \n","                        validation_data=val_gen,\n","                        validation_steps=num_val_batches, \n","                        class_weight=None, \n","                        max_queue_size=10, \n","                        workers=20,\n","                        use_multiprocessing=True, \n","                        shuffle=False, \n","                        initial_epoch=0)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n","Epoch 1/3\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-1f3ca2c8fa96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         initial_epoch=0)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"VzHm9xOyQMiO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":189},"outputId":"eba75c55-1c15-401d-881e-14ea3ab62e39","executionInfo":{"status":"ok","timestamp":1540555332193,"user_tz":-120,"elapsed":578,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["df_test.head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patientId</th>\n","      <th>PatientAge</th>\n","      <th>PatientSex</th>\n","      <th>ViewPosition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000924cf-0f8d-42bd-9158-1af53881a557</td>\n","      <td>19</td>\n","      <td>F</td>\n","      <td>AP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000db696-cf54-4385-b10b-6b16fbb3f985</td>\n","      <td>25</td>\n","      <td>F</td>\n","      <td>AP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000fe35a-2649-43d4-b027-e67796d412e0</td>\n","      <td>40</td>\n","      <td>M</td>\n","      <td>AP</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001031d9-f904-4a23-b3e5-2c088acd19c6</td>\n","      <td>57</td>\n","      <td>M</td>\n","      <td>PA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0010f549-b242-4e94-87a8-57d79de215fc</td>\n","      <td>56</td>\n","      <td>M</td>\n","      <td>PA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              patientId  PatientAge PatientSex ViewPosition\n","0  000924cf-0f8d-42bd-9158-1af53881a557          19          F           AP\n","1  000db696-cf54-4385-b10b-6b16fbb3f985          25          F           AP\n","2  000fe35a-2649-43d4-b027-e67796d412e0          40          M           AP\n","3  001031d9-f904-4a23-b3e5-2c088acd19c6          57          M           PA\n","4  0010f549-b242-4e94-87a8-57d79de215fc          56          M           PA"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1540719590115,"user_tz":-60,"elapsed":167777,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}},"id":"j3pqcZIUTW4i","outputId":"a9dfc839-7f0f-4f02-ea8f-5cf6724ee101","colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["metric_gen = \\\n","val_generator(df_val_images, df_val, 11, num_rows, num_cols)\n","\n","model.load_weights(filepath = 'model_3.h5')\n","predictions = model.predict_generator(metric_gen, \n","                                      steps=len(df_val_images)/11, \n","                                      max_queue_size=5, \n","                                      workers=20, \n","                                      use_multiprocessing=True, \n","                                      verbose=1)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["467/467 [==============================] - 167s 357ms/step\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"ezHyVn2SZCPR","colab":{}},"cell_type":"code","source":["first_outputs = predictions[0]\n","second_outputs = predictions[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oQOlOxYhUe0J","colab_type":"code","colab":{}},"cell_type":"code","source":["predict = []\n","for i in range(len(first_outputs)):\n","  predict.append([np.concatenate((np.array([first_outputs[i][j]]),second_outputs[i][4*j:4*j+4])) for j in range(4)])\n","predict = np.array(predict)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zaERerHuFJF3","colab_type":"code","colab":{}},"cell_type":"code","source":["predict = predict.reshape((predict.shape[0],20))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"onJSbKeXRi1F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"7f314d60-980b-4943-eaf1-19b67b1949f0","executionInfo":{"status":"ok","timestamp":1540719638781,"user_tz":-60,"elapsed":1249,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["predict.shape"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5137, 20)"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"ByUFVxWKE2zz","colab_type":"code","colab":{}},"cell_type":"code","source":["# put the predictions into a dataframe\n","df_preds = pd.DataFrame(predict)\n","\n","# add column names\n","new_names = ['conf_1', 'x_1', 'y_1', 'width_1', 'height_1',\n","            'conf_2', 'x_2', 'y_2', 'width_2', 'height_2',\n","           'conf_3', 'x_3', 'y_3', 'width_3', 'height_3',\n","            'conf_4', 'x_4', 'y_4', 'width_4', 'height_4']\n","\n","df_preds.columns = new_names\n","\n","# add the patientId column\n","df_preds['patientId'] = df_val_images['patientId']\n","\n","# add the PredictionString column\n","df_preds['PredictionString'] = 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u8U4JShpSFN5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":396},"outputId":"d5c1e92b-6f40-459e-a9e0-3a6b8e6112f2","executionInfo":{"status":"ok","timestamp":1540719642074,"user_tz":-60,"elapsed":1230,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["df_preds.iloc[88]"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["conf_1                                          0.355816\n","x_1                                              81.2097\n","y_1                                              107.409\n","width_1                                          90.6456\n","height_1                                         54.9941\n","conf_2                                         0.0983598\n","x_2                                               42.289\n","y_2                                              50.1411\n","width_2                                           74.537\n","height_2                                         42.5337\n","conf_3                                       2.66318e-34\n","x_3                                                    0\n","y_3                                                    0\n","width_3                                                0\n","height_3                                               0\n","conf_4                                                 0\n","x_4                                                    0\n","y_4                                                    0\n","width_4                                                0\n","height_4                                               0\n","patientId           5258e07a-292d-495a-8c66-8cbc9221ec14\n","PredictionString                                       0\n","Name: 88, dtype: object"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"MEM_i9SuF8KG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Version 2: Changes were made. See comments below.\n","\n","def process_preds(df):\n","    \n","    limit = 0.3\n","    \n","    conf_1 = 0\n","    conf_2 = 0\n","    conf_3 = 0\n","    conf_4 = 0\n","    \n","    string_1 = ''\n","    string_2 = ''\n","    string_3 = ''\n","    string_4 = ''\n","    \n","    \n","    for i in range(0,len(df)):\n","      \n","\n","        #get the conf scores\n","        conf_1 = df.loc[i,'conf_1'] # revised in Version 2\n","        conf_2 = df.loc[i,'conf_2'] # revised in Version 2\n","        conf_3 = df.loc[i,'conf_3'] # revised in Version 2\n","        conf_4 = df.loc[i,'conf_4'] # revised in Version 2\n","\n","\n","\n","        if conf_1 >= limit:\n","            string_1 = \\\n","            str(conf_1) + ' ' + str(round(df.loc[i,'x_1']))+ ' ' + \\\n","            str(round(df.loc[i,'y_1']))+ ' ' + str(round(df.loc[i,'width_1']))+ ' ' + str(round(df.loc[i,'height_1']))\n","        else:\n","            string_1 = ''\n","\n","        if conf_2 >= limit:\n","            string_2 = \\\n","            str(conf_2) + ' ' + str(round(df.loc[i,'x_2']))+ ' ' + \\\n","            str(round(df.loc[i,'y_2']))+ ' ' + str(round(df.loc[i,'width_2']))+ ' ' + str(round(df.loc[i,'height_2']))\n","        else:\n","            string_2 = ''\n","\n","        if conf_3 >= limit:\n","            string_3 = \\\n","            str(conf_3) + ' ' + str(round(df.loc[i,'x_3']))+ ' ' + \\\n","            str(round(df.loc[i,'y_3']))+ ' ' + str(round(df.loc[i,'width_3']))+ ' ' + str(round(df.loc[i,'height_3']))          \n","        else:\n","            string_3 = ''\n","\n","        if conf_4 >= limit:\n","            string_4 = \\\n","            str(conf_4) + ' ' + str(round(df.loc[i,'x_4']))+ ' ' + \\\n","            str(round(df.loc[i,'y_4']))+ ' ' + str(round(df.loc[i,'width_4']))+ ' ' + str(round(df.loc[i,'height_4']))\n","        else:\n","            string_4 = ''\n","\n","        df.loc[i,'PredictionString']  = \\\n","        string_1 + ' ' + string_2 + ' ' + string_3 + ' ' + string_4\n","\n","    df_submission = df[['patientId', 'PredictionString']]\n","    \n","    return df_submission\n","\n","# call the function\n","df_submission = process_preds(df_preds)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yiZVYd0sG6Qb","colab_type":"code","colab":{}},"cell_type":"code","source":["ID = df_preds['patientId']\n","preds = df_preds['PredictionString']\n","\n","submission = pd.DataFrame({'patientId':ID, \n","                           'PredictionString':preds, \n","                          }).set_index('patientId')\n","\n","submission.to_csv('pneu_keras_model.csv', columns=['PredictionString']) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"37DzM66seab-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66},"outputId":"42af37d9-b98f-485b-c5c8-0a2c7e6a773d","executionInfo":{"status":"ok","timestamp":1540719659514,"user_tz":-60,"elapsed":672,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["df_submission.iloc[0]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["patientId           06bf9151-5732-4968-b198-f4109676cd55\n","PredictionString       0.3558158 81.0 107.0 91.0 55.0   \n","Name: 0, dtype: object"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"id":"08Yvj2CQejCn","colab_type":"code","colab":{}},"cell_type":"code","source":["df_pred_images = df_preds[['patientId','x_1','y_1','width_1','height_1',\t'x_2',\t'y_2',\t'width_2', 'height_2',\n","                         'x_3',\t'y_3',\t'width_3',\t'height_3',\t'x_4',\t'y_4',\t'width_4',\t'height_4']].sort_values(by='patientId')\n","df_val_images_true = df_val_images[['patientId','x_1','y_1','width_1','height_1',\t'x_2', \t'y_2', 'width_2', 'height_2',\n","                           'x_3',\t'y_3',\t'width_3',\t'height_3',\t'x_4',\t'y_4',\t'width_4',\t'height_4']].sort_values(by='patientId')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KcBMg6LpflYN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":189},"outputId":"9dfe77f3-4de9-4804-adf7-fe75f958a792","executionInfo":{"status":"ok","timestamp":1540719666349,"user_tz":-60,"elapsed":1028,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["df_pred_images.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patientId</th>\n","      <th>x_1</th>\n","      <th>y_1</th>\n","      <th>width_1</th>\n","      <th>height_1</th>\n","      <th>x_2</th>\n","      <th>y_2</th>\n","      <th>width_2</th>\n","      <th>height_2</th>\n","      <th>x_3</th>\n","      <th>y_3</th>\n","      <th>width_3</th>\n","      <th>height_3</th>\n","      <th>x_4</th>\n","      <th>y_4</th>\n","      <th>width_4</th>\n","      <th>height_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>563</th>\n","      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n","      <td>17.199091</td>\n","      <td>16.392096</td>\n","      <td>7.363505</td>\n","      <td>10.344476</td>\n","      <td>2.534106</td>\n","      <td>0.672866</td>\n","      <td>1.448818</td>\n","      <td>0.830888</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2544</th>\n","      <td>00c0b293-48e7-4e16-ac76-9269ba535a62</td>\n","      <td>52.162369</td>\n","      <td>68.631348</td>\n","      <td>53.513210</td>\n","      <td>35.008194</td>\n","      <td>23.380991</td>\n","      <td>20.433475</td>\n","      <td>39.830410</td>\n","      <td>21.041119</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1683</th>\n","      <td>014b7b58-f641-4477-8bbc-ae6f337745d6</td>\n","      <td>57.567154</td>\n","      <td>70.600601</td>\n","      <td>52.594418</td>\n","      <td>39.323650</td>\n","      <td>24.522358</td>\n","      <td>26.725451</td>\n","      <td>41.160927</td>\n","      <td>22.665382</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1290</th>\n","      <td>01a7353d-25bb-4ff8-916b-f50dd541dccf</td>\n","      <td>47.121159</td>\n","      <td>56.946941</td>\n","      <td>42.210941</td>\n","      <td>32.528290</td>\n","      <td>19.734274</td>\n","      <td>24.484505</td>\n","      <td>33.980392</td>\n","      <td>18.591492</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1403</th>\n","      <td>01c09fb1-a917-46ee-8d94-44f844a4eb85</td>\n","      <td>51.734386</td>\n","      <td>67.074409</td>\n","      <td>58.485310</td>\n","      <td>35.059753</td>\n","      <td>28.569372</td>\n","      <td>35.192287</td>\n","      <td>50.349396</td>\n","      <td>28.673100</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 patientId        x_1        y_1    width_1  \\\n","563   003d8fa0-6bf1-40ed-b54c-ac657f8495c5  17.199091  16.392096   7.363505   \n","2544  00c0b293-48e7-4e16-ac76-9269ba535a62  52.162369  68.631348  53.513210   \n","1683  014b7b58-f641-4477-8bbc-ae6f337745d6  57.567154  70.600601  52.594418   \n","1290  01a7353d-25bb-4ff8-916b-f50dd541dccf  47.121159  56.946941  42.210941   \n","1403  01c09fb1-a917-46ee-8d94-44f844a4eb85  51.734386  67.074409  58.485310   \n","\n","       height_1        x_2        y_2    width_2   height_2  x_3  y_3  \\\n","563   10.344476   2.534106   0.672866   1.448818   0.830888  0.0  0.0   \n","2544  35.008194  23.380991  20.433475  39.830410  21.041119  0.0  0.0   \n","1683  39.323650  24.522358  26.725451  41.160927  22.665382  0.0  0.0   \n","1290  32.528290  19.734274  24.484505  33.980392  18.591492  0.0  0.0   \n","1403  35.059753  28.569372  35.192287  50.349396  28.673100  0.0  0.0   \n","\n","      width_3  height_3  x_4  y_4  width_4  height_4  \n","563       0.0       0.0  0.0  0.0      0.0       0.0  \n","2544      0.0       0.0  0.0  0.0      0.0       0.0  \n","1683      0.0       0.0  0.0  0.0      0.0       0.0  \n","1290      0.0       0.0  0.0  0.0      0.0       0.0  \n","1403      0.0       0.0  0.0  0.0      0.0       0.0  "]},"metadata":{"tags":[]},"execution_count":35}]},{"metadata":{"id":"Wv37xmjgg7lP","colab_type":"code","colab":{}},"cell_type":"code","source":["y_true = df_val_images_true.drop('patientId',axis=1).as_matrix()\n","y_pred = df_pred_images.drop('patientId',axis=1).as_matrix()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"3pz6qUPUY-Xa","colab":{}},"cell_type":"code","source":["# IoU metric functions using tf.py_func, as suggested in  Marsh's (@vbookshelf) kernel:\n","#   https://www.kaggle.com/vbookshelf/keras-iou-metric-implemented-without-tensor-drama\n","\n","METRIC_THRESH = 0.3\n","\n","\n","def raw_iou(y_true, y_pred):\n","    results = []\n","    y_pred = y_pred > METRIC_THRESH\n","    for i in range(0,y_true.shape[0]):\n","        intersect = np.sum( y_true[i,:] * y_pred[i,:] )\n","        union = np.sum( y_true[i,:] ) + np.sum( y_pred[i,:] ) - intersect + 1e-7\n","        iou = np.mean((intersect/union)).astype(np.float32)\n","        iou = min(iou, 1)\n","        results.append( iou )\n","    return np.mean( results )\n","\n","def IoU(y_true, y_pred):\n","    iou = tf.py_func(raw_iou, [y_true, y_pred], tf.float32)\n","    return iou"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MLhNmFhNhG7q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"fd28d8d6-2bd1-4e56-f36e-4c259737f67e","executionInfo":{"status":"ok","timestamp":1540561979778,"user_tz":-120,"elapsed":476,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["raw_iou(y_true, y_pred)"],"execution_count":212,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.21667043435705852"]},"metadata":{"tags":[]},"execution_count":212}]},{"metadata":{"id":"7U8xZdqqsPom","colab_type":"code","colab":{}},"cell_type":"code","source":["y_true = y_true.reshape((5137,4,4))\n","y_pred = y_pred.reshape((5137,4,4))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hswV2adxtNCG","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"xNeDcSqPqcOV","colab_type":"code","colab":{}},"cell_type":"code","source":["box_A = df_pred_images.iloc[88][['x_1','y_1','width_1','height_1']]\n","box_B = df_val_images_true.iloc[88][['x_1','y_1','width_1','height_1']]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qX7U4RB8j64M","colab_type":"code","colab":{}},"cell_type":"code","source":["def bb_intersection_over_union(boxA, boxB):\n","    # determine the (x, y)-coordinates of the intersection rectangle\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[0]+boxA[2], boxB[0]+boxB[2])\n","    yB = min(boxA[1]+boxA[3], boxB[1]+boxB[3])\n","    \n","    if xA == 0 and yA == 0 and xB == 0 and yB == 0:\n","        return 0\n","\n","    # compute the area of intersection rectangle\n","    interArea = (xB - xA) * (yB - yA)\n","    #print(interArea)\n","\n","    # compute the area of both the prediction and ground-truth\n","    # rectangles\n","    boxAArea = (boxA[0]+boxA[2] - boxA[0]) * (boxA[1]+boxA[3] - boxA[1])\n","    boxBArea = (boxB[0]+boxB[2] - boxB[0]) * (boxB[1]+boxB[3] - boxB[1])\n","    \n","    if boxAArea + boxBArea - interArea < interArea:\n","      return 0\n","\n","    # compute the intersection over union by taking the intersection\n","    # area and dividing it by the sum of prediction + ground-truth\n","    # areas - the interesection area\n","    iou = interArea / float(boxAArea + boxBArea - interArea + 1)\n","    #print(iou)\n","\n","\n","    # return the intersection over union value\n","    return iou"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L3XgnHzV_1ZK","colab_type":"code","colab":{}},"cell_type":"code","source":["import itertools"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S7e2YW7Ut14J","colab_type":"code","colab":{}},"cell_type":"code","source":["results = []\n","for k in range(len(y_true)):\n","  for i in itertools.product(y_true[k], y_pred[k], range(1)):\n","    results.append(bb_intersection_over_union(i[0],i[1]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u-LqpMa6HsKH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"92a78022-deea-46cd-cf94-f50fd8eaa0b3","executionInfo":{"status":"ok","timestamp":1540721563973,"user_tz":-60,"elapsed":944,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["bb_intersection_over_union(y_true[0][1], y_pred[0][1])"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":80}]},{"metadata":{"id":"cIqZqumPHyUh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"752c3bde-88fc-4b9a-8c20-2700c99f0659","executionInfo":{"status":"ok","timestamp":1540720906073,"user_tz":-60,"elapsed":612,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["y_pred[0][0]"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([17.199091 , 16.392096 ,  7.3635054, 10.344476 ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":57}]},{"metadata":{"id":"ABEsySZhHaF0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"dd67fe08-e20b-48b5-ac41-7b8502b0c104","executionInfo":{"status":"ok","timestamp":1540721583713,"user_tz":-60,"elapsed":599,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["bb_intersection_over_union([571.4, 275.1, 230.8, 476.2], [571.4, 275.1, 230.8, 476.2])"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999909014779276"]},"metadata":{"tags":[]},"execution_count":83}]},{"metadata":{"id":"Htl1rsaCHhpu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1666},"outputId":"6cc213bf-06bc-4a91-fb14-ceaa6059f4b1","executionInfo":{"status":"ok","timestamp":1540721591327,"user_tz":-60,"elapsed":992,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["results[:100]"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"metadata":{"tags":[]},"execution_count":85}]},{"metadata":{"id":"G8rVLzADuYDr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"a78cc470-e59c-4b89-ec3b-e861f2100198","executionInfo":{"status":"ok","timestamp":1540721597962,"user_tz":-60,"elapsed":917,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["np.mean(results)"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.010423116708797739"]},"metadata":{"tags":[]},"execution_count":86}]},{"metadata":{"id":"cebdYQN9rBmX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":162},"outputId":"bd7f02ba-ab25-4390-f8d5-098bd318e642","executionInfo":{"status":"error","timestamp":1540668806188,"user_tz":-120,"elapsed":795,"user":{"displayName":"Jannes Germishuys","photoUrl":"https://lh4.googleusercontent.com/--5igECGksuo/AAAAAAAAAAI/AAAAAAAAAOU/Pv9Wcy9YS2A/s64/photo.jpg","userId":"08590290642372462644"}}},"cell_type":"code","source":["y_true[0]"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b82b56cf416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"]}]},{"metadata":{"id":"_RyqG5A2BFA3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}